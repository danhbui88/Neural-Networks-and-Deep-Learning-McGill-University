import numpy as np
import time
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from keras.layers import InputLayer
from keras.layers import Dense, BatchNormalization, Dropout, Flatten
from keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from keras.layers.pooling import MaxPooling2D
from keras.utils import np_utils, to_categorical
import tensorflow.keras.backend as K

#Getting data from cifar-10 dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

#Display the first 9 images
fig = plt.figure()
for i in range(9):
  plt.subplot(3,3,i+1)
  plt.tight_layout()
  plt.imshow(x_train[i], interpolation='none')
  plt.title("Digit: {}".format(y_train[i]))
  plt.xticks([])
  plt.yticks([])

#Check the shape of the input
x_train.shape,y_train.shape,x_test.shape,y_test.shape

#Normalize data
x_train=x_train/255
print(x_train.shape,y_train.shape)

#For unknown reason, my tensorflow API failed to run. I had to force it to work by calling tf._api.v1.keras.layers
tf=tf._api.v1.keras.layers
early_stopping_monitor=EarlyStopping(monitor='val_acc',patience=5)

#Create the model
K.clear_session()
model=Sequential()
model.add(tf.InputLayer((32,32,3)))
model.add(tf.Conv2D(64, (3,3), padding='same', activation='relu',input_shape=(32,32,3)))

model.add(tf.MaxPooling2D(pool_size=(2,2)))
model.add(tf.Dropout(0.25))

model.add(tf.Conv2D(128, (3,3), padding='same', activation='relu'))
model.add(tf.Conv2D(128, (3,3), activation='relu'))
model.add(tf.MaxPooling2D(pool_size=(2,2)))
model.add(tf.Dropout(0.25))

model.add(tf.Conv2D(256, (3,3), padding='same', activation='relu'))
model.add(tf.Conv2D(256, (3,3), activation='relu'))
model.add(tf.MaxPooling2D(pool_size=(2,2)))
model.add(tf.Dropout(0.25))

model.add(tf.Flatten())
model.add(tf.Dropout(0.5))
model.add(tf.BatchNormalization())
model.add(tf.Dense(1024,activation='relu'))
model.add(tf.Dropout(0.5))
model.add(tf.Dense(512,activation='relu'))
model.add(tf.Dropout(0.5))
model.add(tf.Dense(256,activation='relu'))
model.add(tf.Dropout(0.5))
model.add(tf.Dense(10, activation='softmax'))
model.compile(optimizer=Adam(lr=0.0001,decay=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])

#Check the model summary
model.summary()

#Train the model and see how long it takes to do the task
start = time.time()
h=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_split=0.2, shuffle=True,callbacks=[early_stopping_monitor])
end = time.time()
print("Model took %0.2f seconds to train"%(end - start))

#evaluate the test data
loss, accuracy = model.evaluate(x_test/255,y_test)
print('Accuracy on test data %0.2f'%accuracy)

#Save model
model.save('CNN_Cifar10.h5')

#Plot model accuracy
plt.plot(h.history['acc'],label='Train accuracy')
plt.plot(h.history['val_acc'],label='Val accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Train','Test'],loc='best')
plt.show()

#Plot model loss
plt.plot(h.history['loss'],label='Train loss')
plt.plot(h.history['val_loss'],label='Val loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Train','Test'],loc='best')
plt.show()


  
