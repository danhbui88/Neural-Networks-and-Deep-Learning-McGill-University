# -*- coding: utf-8 -*-
"""Minh Bui - Assignment Week 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cfc1b2jaLM5NKCLukF6oGkO93AyCnU_x
"""

import numpy as np
import time
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from keras.layers import InputLayer
from keras.layers import Dense, BatchNormalization, Dropout, Flatten
from keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from keras.layers.pooling import MaxPooling2D
from keras.utils import np_utils, to_categorical
import tensorflow.keras.backend as K

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

fig = plt.figure()
for i in range(9):
  plt.subplot(3,3,i+1)
  plt.tight_layout()
  plt.imshow(x_train[i], interpolation='none')
  plt.title("Digit: {}".format(y_train[i]))
  plt.xticks([])
  plt.yticks([])

x_train.shape,y_train.shape,x_test.shape,y_test.shape

#One hot coding for y_train and y_test
classes=10
y_train=np_utils.to_categorical(y_train,classes)
y_test=np_utils.to_categorical(y_test,classes)
y_train.shape,y_test.shape

#Normalize data
x_train=x_train/255
print(x_train.shape,y_train.shape)

#For unknown reason, my tensorflow API failed to run. I had to force it to work by calling tf._api.v1.keras.layers
  tf=tf._api.v1.keras.layers
  early_stopping_monitor=EarlyStopping(monitor='val_acc',patience=5)

K.clear_session()
model=Sequential()
model.add(tf.InputLayer((32,32,3)))
model.add(tf.Conv2D(64, (3,3), padding='same', activation='relu',input_shape=(32,32,3)))

model.add(tf.MaxPooling2D(pool_size=(2,2)))
model.add(tf.Dropout(0.25))

model.add(tf.Conv2D(128, (3,3), padding='same', activation='relu'))
model.add(tf.Conv2D(128, (3,3), activation='relu'))
model.add(tf.MaxPooling2D(pool_size=(2,2)))
model.add(tf.Dropout(0.25))

model.add(tf.Conv2D(256, (3,3), padding='same', activation='relu'))
model.add(tf.Conv2D(256, (3,3), activation='relu'))
model.add(tf.MaxPooling2D(pool_size=(2,2)))
model.add(tf.Dropout(0.25))

model.add(tf.Flatten())
model.add(tf.Dropout(0.5))
model.add(tf.BatchNormalization())
model.add(tf.Dense(1024,activation='relu'))
model.add(tf.Dropout(0.5))
model.add(tf.Dense(512,activation='relu'))
model.add(tf.Dropout(0.5))
model.add(tf.Dense(256,activation='relu'))
model.add(tf.Dropout(0.5))
model.add(tf.Dense(10, activation='softmax'))
model.compile(optimizer=Adam(lr=0.0001,decay=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

start = time.time()
h=model.fit(x_train, y_train, batch_size=128, epochs=100, verbose=1, validation_split=0.2, shuffle=True,callbacks=[early_stopping_monitor])
end = time.time()
print("Model took %0.2f seconds to train"%(end - start))

loss, accuracy = model.evaluate(x_test/255,y_test)

print('Accuracy on test data %0.2f'%accuracy)

model.save('CNN_Cifar10.h5')

plt.plot(h.history['acc'],label='Train accuracy')
plt.plot(h.history['val_acc'],label='Val accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Train','Test'],loc='best')
plt.show()

plt.plot(h.history['loss'],label='Train loss')
plt.plot(h.history['val_loss'],label='Val loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Train','Test'],loc='best')
plt.show()